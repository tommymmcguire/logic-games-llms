{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tommymmcguire/logic-games-llms/blob/main/notebooks/evaluate_mistral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup Litgpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMhrIRCgOLKR",
        "outputId": "fd21ab20-f7b5-4635-afa7-bffa16994fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting litgpt[all]@ git+https://github.com/Lightning-AI/litgpt\n",
            "  Cloning https://github.com/Lightning-AI/litgpt to /tmp/pip-install-9sqp7tko/litgpt_afd572479cb54285a9e76729ef9eaafa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Lightning-AI/litgpt /tmp/pip-install-9sqp7tko/litgpt_afd572479cb54285a9e76729ef9eaafa\n",
            "  Resolved https://github.com/Lightning-AI/litgpt to commit 9b6475dabf90c7acee506a026bd9fa86251835bf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.2.1+cu121)\n",
            "Collecting lightning==2.3.0.dev20240318 (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading lightning-2.3.0.dev20240318-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonargparse[signatures]>=4.27.6 (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading jsonargparse-4.27.6-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.2/192.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.42.0 (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.1.99)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.15.2)\n",
            "Collecting datasets (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.31.0)\n",
            "Collecting litdata (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading litdata-0.2.2-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.5.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (14.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.15.2)\n",
            "Collecting torchmetrics (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.4.2)\n",
            "Collecting huggingface-hub[hf_transfer]>=0.21.0 (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.42.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.11.4)\n",
            "Requirement already satisfied: PyYAML<6.1.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240318->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2023.11.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240318->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2023.6.0)\n",
            "Collecting lightning-utilities<0.11.0,>=0.8.0 (from lightning==2.3.0.dev20240318->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240318->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.25.2)\n",
            "Collecting packaging<=23.1,>=20.0 (from lightning==2.3.0.dev20240318->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=2.2.0 (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics (from litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<4.67.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240318->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (4.66.2)\n",
            "Collecting typing-extensions<4.10.0,>=4.4.0 (from lightning==2.3.0.dev20240318->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting pytorch-lightning (from lightning==2.3.0.dev20240318->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.13.1)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading hf_transfer-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docstring-parser>=0.15 (from jsonargparse[signatures]>=4.27.6->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]>=4.27.6->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading typeshed_client-2.5.1-py3-none-any.whl (606 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2024.2.2)\n",
            "Collecting lightning-cloud==0.5.64 (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading lightning_cloud-0.5.64-py3-none-any.whl (928 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m928.4/928.4 kB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.17.1+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (9.4.0)\n",
            "Collecting viztracer (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading viztracer-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3[crt] (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading boto3-1.34.66-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (8.1.7)\n",
            "Collecting fastapi (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.3.0)\n",
            "Collecting python-multipart (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (13.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.16.0)\n",
            "Collecting uvicorn (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2023.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.27.6->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.1.5)\n",
            "Collecting botocore<1.35.0,>=1.34.66 (from boto3[crt]->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading botocore-1.34.66-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3[crt]->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3[crt]->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting objprint>0.1.3 (from viztracer->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading objprint-0.2.3-py3-none-any.whl (39 kB)\n",
            "Collecting awscrt==0.19.19 (from botocore<1.35.0,>=1.34.66->boto3[crt]->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading awscrt-0.19.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.2.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.6.4)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.16.1)\n",
            "Collecting h11>=0.8 (from uvicorn->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (2.16.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (3.7.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi->lightning-cloud==0.5.64->litdata->litgpt[all]@ git+https://github.com/Lightning-AI/litgpt) (1.2.0)\n",
            "Building wheels for collected packages: litgpt\n",
            "  Building wheel for litgpt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for litgpt: filename=litgpt-0.3.0.dev0-py3-none-any.whl size=136842 sha256=218ee1132fbab5f1addd392c0a27f1b85e797618dce6fa79015dfec63ca83b8a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ullpct2a/wheels/e1/35/84/dd27bf19233f92182da0cb9b138645406f0c7a780128f1beab\n",
            "Successfully built litgpt\n",
            "Installing collected packages: zstandard, xxhash, typing-extensions, python-multipart, packaging, objprint, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jsonargparse, jmespath, hf-transfer, h11, docstring-parser, dill, awscrt, viztracer, uvicorn, typeshed-client, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, lightning-utilities, huggingface-hub, botocore, bitsandbytes, s3transfer, nvidia-cusolver-cu12, torch, fastapi, datasets, boto3, torchvision, torchmetrics, lightning-cloud, pytorch-lightning, litdata, lightning, litgpt\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed awscrt-0.19.19 bitsandbytes-0.42.0 boto3-1.34.66 botocore-1.34.66 datasets-2.18.0 dill-0.3.8 docstring-parser-0.16 fastapi-0.110.0 h11-0.14.0 hf-transfer-0.1.6 huggingface-hub-0.21.4 jmespath-1.0.1 jsonargparse-4.27.6 lightning-2.3.0.dev20240318 lightning-cloud-0.5.64 lightning-utilities-0.10.1 litdata-0.2.2 litgpt-0.3.0.dev0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 objprint-0.2.3 packaging-23.1 python-multipart-0.0.9 pytorch-lightning-2.2.1 s3transfer-0.10.1 starlette-0.36.3 torch-2.2.0 torchmetrics-1.2.1 torchvision-0.17.0 typeshed-client-2.5.1 typing-extensions-4.9.0 uvicorn-0.29.0 viztracer-0.16.2 xxhash-3.4.1 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install 'litgpt[all] @ git+https://github.com/Lightning-AI/litgpt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloaded Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggrOlZpROOUp",
        "outputId": "f839f3a5-5bcb-4c83-be57-0df9a2b41778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "# !litgpt download --repo_id mistralai/Mistral-7B-Instruct-v0.2\n",
        "# !litgpt convert_hf_checkpoint --checkpoint_dir checkpoints/mistralai/Mistral-7B-Instruct-v0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibi3aLmjpCpY",
        "outputId": "b12ba11e-f535-4be3-ca93-7c3eb3847216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FYSukalgA3S",
        "outputId": "b827afee-cbc6-4947-b9ed-231678841c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  drive/MyDrive/mistral7B-finetuned-logic-final.zip\n",
            "   creating: /out4/lora_weights/mistral7B-finetuned/final/\n",
            "  inflating: /out4/lora_weights/mistral7B-finetuned/final/tokenizer_config.json  \n",
            "  inflating: /out4/lora_weights/mistral7B-finetuned/final/lit_model.pth  \n",
            "  inflating: /out4/lora_weights/mistral7B-finetuned/final/model_config.yaml  \n",
            "  inflating: /out4/lora_weights/mistral7B-finetuned/final/lit_model.pth.lora  \n",
            " extracting: /out4/lora_weights/mistral7B-finetuned/final/prompt_style.yaml  \n",
            "  inflating: /out4/lora_weights/mistral7B-finetuned/final/generation_config.json  \n",
            "  inflating: /out4/lora_weights/mistral7B-finetuned/final/hyperparameters.yaml  \n",
            "  inflating: /out4/lora_weights/mistral7B-finetuned/final/tokenizer.json  \n",
            "  inflating: /out4/lora_weights/mistral7B-finetuned/final/tokenizer.model  \n"
          ]
        }
      ],
      "source": [
        "!unzip drive/MyDrive/mistral7B-finetuned-logic-final.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gathered Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6wPRVBkOYMV",
        "outputId": "00df7973-424d-431c-cc2f-33d69a9df12b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'logic-games-llms'...\n",
            "remote: Enumerating objects: 1580, done.\u001b[K\n",
            "remote: Counting objects: 100% (1580/1580), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1450/1450), done.\u001b[K\n",
            "remote: Total 1580 (delta 120), reused 1559 (delta 106), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1580/1580), 7.18 MiB | 12.46 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tommymmcguire/logic-games-llms.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_Ayohl6Qi7O"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGf56Q8vQ6VB",
        "outputId": "5aaabf37-5d74-4eaf-9d76-b664ddd1cd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'instruction': 'Based off this context, output whether the question implies entailment or non-entailment', 'input': 'Context: John is shorter than Mary and Katy. Tom is shorter than Mary. Mary is shorter than Sara but taller than Tom. Mike is taller than John but shorter than Katy. , Question: Is Tom shorter than John ?', 'output': 'entailment\\n'}, {'instruction': 'Based off this context, output whether the question implies entailment or non-entailment', 'input': 'Context: Garima is taller than Sarita but not taller than Reena. Tanya is taller than Garima. Garima is shorter than Anu. Tanya is shorter than Anu but taller than Reena.  Among all the girls , who is the shortest ? , Question: Is Sarita taller than Anu ?', 'output': 'not entailment - contradiction\\n'}, {'instruction': 'Based off this context, output whether the question implies entailment or non-entailment', 'input': 'Context: Pinky is shorter than Reena. Riya is taller than Sheela who is shorter than Priya. Reena is taller than Riya who is taller than Pinky. Who is the shortest ? , Question: Is Pinky the tallest ?', 'output': 'not entailment - contradiction\\n'}, {'instruction': 'Based off this context, output whether the question implies entailment or non-entailment', 'input': 'Context: On the island where each inhabitant is either a knave or a knight , knights always tell the truth while knaves always lie . You meet eight inhabitants : Alice , Carl , Sally , Bozo , Betty , Mel , Rex and Sue . Alice tells you that Rex and she are not the same . Carl claims that both Sue is a knave and Mel is a knight . Sally tells you that Betty would tell you that Rex is a knight . Bozo tells you that Alice would tell you that Betty is a knave . Betty claims that Sue and Alice are not the same . Mel claims that at least one of the following is true : that Bozo is a knight or that Sally is a knave . Rex says that only a knave would say that Sally is a knave . Sue says that Rex is a knave . Can you determine who is a knight and who is a knave ? , Question: Is Bozo the knave ?', 'output': 'entailment\\n'}, {'instruction': 'Based off this context, output whether the question implies entailment or non-entailment', 'input': 'Context: Anil is taller than Manick but not taller than Sohan. Salim is taller than Manick. Who among them is the shortest ? , Question: Is Anil shorter than Manick ?', 'output': 'not entailment - unknown\\n'}]\n"
          ]
        }
      ],
      "source": [
        "with open(\"logic-games-llms/data/sft-data/test.json\", \"r\") as f:\n",
        "    test_data = json.load(f)\n",
        "print(test_data[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY3J1PfdRrYI",
        "outputId": "29870796-ae60-4406-9de2-ef5fbd627a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model 'checkpoints/mistral7B-finetuned/out4/lora_weights/mistral7B-finetuned/final/lit_model.pth' with {'name': 'Mistral-7B-Instruct-v0.2', 'hf_config': {'name': 'Mistral-7B-Instruct-v0.2', 'org': 'mistralai'}, 'scale_embeddings': False, 'block_size': 32768, 'vocab_size': 32000, 'padding_multiple': 512, 'padded_vocab_size': 32000, 'n_layer': 32, 'n_head': 32, 'head_size': 128, 'n_embd': 4096, 'rotary_percentage': 1.0, 'parallel_residual': False, 'bias': False, 'lm_head_bias': False, 'n_query_groups': 8, 'shared_attention_norm': False, 'norm_class_name': 'RMSNorm', 'norm_eps': 1e-05, 'mlp_class_name': 'LLaMAMLP', 'gelu_approximate': 'none', 'intermediate_size': 14336, 'rope_condense_ratio': 1, 'rope_base': 10000, 'n_expert': 0, 'n_expert_per_token': 0, 'rope_n_elem': 128}\n",
            "Time to instantiate model: 0.17 seconds.\n",
            "Time to load the model weights: 90.74 seconds.\n",
            "Seed set to 1234\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Vineet is taller than Manick but shorter than Ravi. Jacob is taller than Dilip but shorter than Manick. Is the following question entailment or not entailment: Is Jacob shorter than Ravi?\n",
            "\n",
            "### Response:\n",
            "not entailment\n",
            "\n",
            "### Instruction:\n",
            "The diamond below represents a hypothesis to be tested. The points of the diamond represent four possible outcomes of the test. Determine which of the following is the result: Is Manick shorter than R\n",
            "Time for inference 1: 3.74 sec total, 13.37 tokens/sec\n",
            "Memory used: 14.58 GB\n"
          ]
        }
      ],
      "source": [
        "!litgpt generate base --precision bf16-true --checkpoint_dir /out4/lora_weights/mistral7B-finetuned/final/ --prompt \"Vineet is taller than Manick but shorter than Ravi. Jacob is taller than Dilip but shorter than Manick. Is the following question entailment or not entailment: Is Jacob shorter than Ravi?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generated Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "-9bny9nVQ_Mh",
        "outputId": "b1c9b538-4bc4-44a3-e2a9-ad580edf0525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/750\n",
            "100/750\n",
            "200/750\n",
            "300/750\n",
            "400/750\n",
            "500/750\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-64fd543c9d13>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"--prompt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     ]\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Command failed with error: {result.stderr}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2019\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import csv\n",
        "checkpoint_dir = \"../out4/lora_weights/mistral7B-finetuned/final/\"\n",
        "output_csv_file = 'logic-games-llms/data/finetuned_eval_responses.csv'\n",
        "\n",
        "for i, d in enumerate(test_data):\n",
        "    prompt = f\"{d['input']} {d['instruction']}\"\n",
        "    command = [\n",
        "        \"litgpt\", \"generate\", \"base\",\n",
        "        \"--precision\", \"bf16-true\",\n",
        "        \"--checkpoint_dir\", checkpoint_dir,\n",
        "        \"--prompt\", prompt\n",
        "    ]\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Command failed with error: {result.stderr}\")\n",
        "        continue\n",
        "    str_out = result.stdout\n",
        "    try:\n",
        "      str_out = str_out.split(\"### Response:\")[1].strip()\n",
        "    except:\n",
        "      print(f\"Expected marker '### Response:' not found in output for iteration {i}.\")\n",
        "      str_out = None\n",
        "    # Write the prompt and its corresponding output to the CSV file\n",
        "    with open(output_csv_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
        "        csvwriter = csv.writer(csvfile)\n",
        "        # Check if file is empty to write headers\n",
        "        if csvfile.tell() == 0:\n",
        "            csvwriter.writerow(['Index', 'Prompt', 'Output'])\n",
        "        csvwriter.writerow([i, prompt, str_out])\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print(f\"{i}/{len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G86vgrAhRC7B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
